# Patrick
自动化资产监控，漏扫平台


## 后端框架选择（已暂时弃用python）

1. web框架使用fastapi，对比flask和django的restapi，这个更简单，更现代化，异步，更快速
2. 数据库选用mongodb，fastapi是异步框架，适合配合motor操作mongodb（mongodb比较适合这种数据储存，后面可能会再配合es使用）
3. 难受的是motor不支持模型，pymongo支持model，但不支持异步，但最终决定硬着头皮使用motor，因为数据库操作不是很多
4. 任务队列使用dramatiq，相较于cerely更新，但难受的是，它不是异步操作

## 前端框架选择

ant design pro框架挺好看，功能强大，有官方维护
前端在vue和react上选择，vue比较新，更简单，开发效率更高，选用vue，拥抱新技术

## 语言选择

java和python语言之间做纠结  

java优势：

1. 但python是动态类型语言，java是静态，又有作用域，使用java代码开发代码提示会很舒服
2. java分布式相关框架都很成熟，丰富，可选择度高，更结构化，java是最适合写项目的，java yyds！

python优势

1. 服务端和worker语言相同，模型可以复用
2. 有任务队列框架，服务端和worker可以复用代码，开发更方便
3. json可以和字典互相转换，字典是python基本类型，而java是用字典需要类包装

其实开发难度上java和python是相同的
python的任务队列框架，不需要手动解析消息队列，和worker可以代码复用
如果项目大，那java会更方便，更结构化

开始用java写了一个版本服务端，现在转python了，因为服务端复杂度不是很高,还是服务端和worker使用同一套代码吧
如果复杂度变高，性能要求变高，再转java

------

一周后

我又转java了

python任务队列框架对消息队列进行了封装，使用时感受不到消息队列存在，很方便

但，节点完成扫描任务后，不能直接将结果返回给服务端，需要直连数据库，写入结果数据，这就可能导致节点过多时，多个节点反复连接数据库，多次同时写入，对数据库造成压力

可以使用消息队列，将结果写入队列，一个节点监听结果队列，写入数据库，达到消锋的目的

因为还是避免不了对消息队列直接操作，所以不如直接用java了

java的rpc框架dubbo可以异步调用，发出任务，完成后服务端回调函数做写入数据库等操作，，完全满足我的需求，可惜，只支持java语言，那就需要worker节点使用java完成，但是java语言不能做到半连接扫描（但可以配合其他语言实现）

worker复杂度不高，暂时先用python完成，后面可能整个项目都用java实现


## 消息队列选择

需要支持跨平台
暂时从redis和rabbitmq中选择

rabbitmq包含消息确认，当多个worker监听同一个队列时，可能会导致多个worker取得同一条任务进行消费，导致资源浪费
redis做消息队列，小巧方便，功能简单，刚好满足需求，而且可以做缓存

## 任务队列框架

celery和dramatiq
网上celery资料比较多，经典，但是相比dramatiq使用繁琐，而且听说有队列不消费的问题

所以尝试使用dramatiq，官方文档比较详细
官方推荐配合APScheduler，实现定时任务

## 数据库选择

可能用于测绘，数据量会比较大，而且需要频繁搜索数据，所以采用elasticsearch+mongodb组合

## 扫描器

两个方案，暂时使用第二个，后期稳定，再改第一个

1. go自研的扫描器，生成动态库调用
2. 使用nmap+masscan

## redis缓存

为了防止任务重复添加，造成不必要的资源消耗，在服务端和mongodb间使用redis做缓存，为了保证扫描结果的实时性，每次的扫描任务只会在redis缓存10天

## 日志

java的spring框架的aop特别方便，项目开发好后，可以根据需要在不改变原代码情况下为某功能增加日志
worker端就记录下收到任务、扫描结果、时间等信息

## 架构

### 方案一

1. 消息队列做为worker和服务端通讯，共有**三种队列**，1. 任务队列，每种worker监听对应的任务队列，接收任务，2. 所有worker监听一个指令队列，用于接收服务端的指令 3. 所有worker监听回传队列，可用于扫描结果回传，状态报告等
2. 服务端前后端分离，只有服务端对数据库做读写操作

消息队列与worker配合实现了一个类似异步rpc调用的功能，结构简单清晰，不影响后续开发扩充

![image-20220212203246463](https://image.3001.net/images/20220212/1644677400_6207c9185668edbb2112d.png)



### 方案二 
arl（https://github.com/TophantTechnology/ARL）采用的这种结构

arl的结构如图，缺点有

1. worker直接与mongodb相连，worker节点过多会导致mongodb压力过大，不稳定
2. 是如果worker端被攻陷，会影响数据安全

![image-20220212202906210](https://image.3001.net/images/20220212/1644677400_6207c918b23dff51e321c.png)


### 方案三

上面几种结构都是通过消息队列发布任务，优点是不需要考虑任务分发，但缺乏对节点的掌控。单台机器还好，如果worker节点多了，例如发布一个任务，得到的结果有错误或扫描结果不准确（或者根本发现不了有节点挂掉了，例如有节点扫描器出现问题，只消费，不出结果。这种情况很难发现，只是少了一些扫描结果，导致整个平台扫描结果不准确），那排查故障的worker节点也会非常困难，看不到每个任务是哪台机器消费的（消息队列可能可以看到？）

如果是一对一任务发布，那某台机器挂了，失联了，可以立刻发现，机器还可以向服务端发送心跳，汇报当前系统状态，很方便


结构如图（基于http协议的伪rpc框架）

java有很多成熟的分布式框架，可以使用nacos+foreign+sentinel实现，既可以高度解耦，维护、排查问题方便，又有高可用

服务端对任务解析，任务分配时，尽可能的将同一个ip的任务均匀分配到所有机器（防止同一时间某ip的请求频率过高导致ip被封）

并根据worker完成时间，判断worker的网络环境，完成效率等做数据分析，自动调整worker的任务量，达到最高效

任务的扫描结果回传，可以使用redis做消息队列，接收扫描结果

后面还可以定时获取worker的状态，如cpu占用，带宽占用等信息。根据这些信息调整机器参数、分配服务。如性能过剩，则降低机器配置或同时搭建其他服务，提高资源利用率，节约成本



![image-20220212221519467](https://image.3001.net/images/20220212/1644677401_6207c91922a9010137e05.png)



## 问题

如果worker故障导致任务丢失怎么办？

消息队列将任务分发下去，rabbitmq有消息确认机制，只保证消息不会丢失，不保证消息不重复，所以多个worker监听同一个队列，可能会收到同一个任务，导致重复消费，造成资源浪费

如果没有消息确认机制，那如果某台机器挂了，但还在消费，就会导致任务丢失

暂时想法是服务端将发布出的任务暂存到内存，设置超时时间，如果未收到任务结果，则再将任务发布，并发出警告，可能有节点存在故障

当然这个问题使用上面的第三种结构就不存在

